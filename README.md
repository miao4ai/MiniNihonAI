# MiniNihonAI

> Lightweight AI Infrastructure for Japanese-Language Applications

---

## Overview

**MiniNihonAI** is a lightweight, modular AI infrastructure built to support Japanese-language AI applications, with features optimized for local deployment (e.g., RTX 4090) and optional cloud extensions. This repo focuses solely on the infrastructure layer, and is designed to serve as a backend engine for applications such as semantic search, tourism assistants, RAG systems, and multimodal chat.

> Future apps (like **"Nihon Travel Buddy" / æ—¥æœ¬è²¼å¿ƒæ—…éŠé†¬**) will utilize this infra to provide actual services and user interfaces.

---

## Core Features

- âœ… Lightweight deployment on a single GPU (e.g., RTX 4090)
- âœ… Support for Japanese LLMs (Phi-2, Mistral 7B, etc.)
- âœ… Pluggable embedding models (SBERT, OpenCLIP)
- âœ… Optional multimodal processing (CLIP, BLIP2)
- âœ… Vector DB integration (FAISS or Qdrant)
- âœ… RAG pipeline with retriever abstraction
- âœ… FastAPI-based RESTful API for downstream app consumption
- âœ… Configurable cloud deployment scripts (AWS / Docker Compose)

---

## Directory Structure (Full)

```
MiniNihonAI/
â”œâ”€â”€ api/                        # FastAPI server and route logic
â”‚   â””â”€â”€ main.py                # Entry point for API
â”‚   â””â”€â”€ routers/               # Route modules
â”‚       â””â”€â”€ qa_router.py       # QA endpoint logic
â”‚
â”œâ”€â”€ configs/                   # Configurations
â”‚   â””â”€â”€ config.yaml            # All model and service configs
â”‚
â”œâ”€â”€ data/                      # Data storage and examples
â”‚   â”œâ”€â”€ documents/             # Raw and cleaned knowledge docs
â”‚   â”œâ”€â”€ images/                # Sample tourist images
â”‚   â””â”€â”€ index/                 # FAISS / Qdrant vector indexes
â”‚
â”œâ”€â”€ deploy/                    # Deployment scripts
â”‚   â”œâ”€â”€ docker-compose.yml     # Docker infra
â”‚   â””â”€â”€ aws_launcher.sh        # AWS EC2 setup script
â”‚
â”œâ”€â”€ models/                    # Model loaders
â”‚   â”œâ”€â”€ llm_loader.py          # Load and run LLMs
â”‚   â”œâ”€â”€ embed_loader.py        # Load embedding models
â”‚   â”œâ”€â”€ clip_loader.py         # For multimodal (image-text)
â”‚   â””â”€â”€ translator.py          # Optional multilingual tools
â”‚
â”œâ”€â”€ rag/                       # Retrieval-Augmented Generation
â”‚   â”œâ”€â”€ retriever.py           # Vector search logic
â”‚   â””â”€â”€ rag_pipeline.py        # QA pipeline with generator
â”‚
â”œâ”€â”€ ui/                        # (Optional) Gradio/Streamlit UI
â”‚   â”œâ”€â”€ gradio_ui.py
â”‚   â””â”€â”€ streamlit_ui.py
â”‚
â”œâ”€â”€ utils/                     # Utilities
â”‚   â”œâ”€â”€ logger.py              # Logging utility
â”‚   â”œâ”€â”€ splitter.py            # Text splitter for RAG
â”‚   â””â”€â”€ file_loader.py         # File and doc loader
â”‚
â”œâ”€â”€ vector_store/             # Vector DB interfaces
â”‚   â”œâ”€â”€ faiss_engine.py        # FAISS wrapper
â”‚   â””â”€â”€ qdrant_engine.py       # Qdrant wrapper
â”‚
â”œâ”€â”€ logs/                     # Logging outputs
â”‚
â”œâ”€â”€ .env                      # Environment variables (API keys, etc)
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md
```

---

## Use Cases (Supported by Infra)

While this repo is not an app itself, it enables downstream applications such as:

- ğŸ—ºï¸ **Tourism Assistants** â€“ Japanese Q&A over local spots
- ğŸ–¼ï¸ **Multimodal Search** â€“ Upload images and retrieve nearby locations
- ğŸ’¬ **RAG QA Bots** â€“ Enhanced Q&A with document retrieval
- ğŸˆ³ **Local Language Models** â€“ Japanese GPT inference on edge

---

## Future Integration Example

A separate application, e.g. `nihon-travel-buddy`, will:
- Call `MiniNihonAI` REST APIs for LLM inference and search
- Provide a frontend (web, mobile, or chatbot)
- Possibly trigger fine-tuning or retraining via this infra

---

## Deployment Targets

- âœ… Local machine (Linux with CUDA, Windows WSL2 supported)
- âœ… Docker Compose setup
- ğŸ”œ AWS EC2 GPU spot instance launcher

---

## License

MIT License (c) 2025 Miao Jiang

